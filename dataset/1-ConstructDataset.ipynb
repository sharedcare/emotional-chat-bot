{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sw/centos/anaconda3/2019.10/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DailyDialog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text in trainset\n",
    "trainset_text = []\n",
    "with open('./ijcnlp_dailydialog/train/dialogues_train.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        assert isinstance(line, str)\n",
    "        trainset_text.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 11118 lines of data in the training set, each line forms a dialogue\n"
     ]
    }
   ],
   "source": [
    "print(\"Totally {} lines of data in the training set, each line forms a dialogue\".format(len(trainset_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Frank â€™ s getting married , do you believe this ? __eou__ Is he really ? __eou__ Yes , he is . He loves the girl very much . __eou__ Who is he marring ? __eou__ A girl he met on holiday in Spain , I think . __eou__ Have they set a date for the wedding ? __eou__ Not yet . __eou__'"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_text[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_utterance = []\n",
    "for i in range(len(trainset_text)):\n",
    "    cur_utterance = trainset_text[i].split(\"__eou__\")\n",
    "    clean_utterance = []\n",
    "    for i in range(len(cur_utterance)):\n",
    "        if cur_utterance[i] != \"\":\n",
    "            clean_utterance.append(cur_utterance[i].strip())\n",
    "        else:\n",
    "            pass\n",
    "    trainset_utterance.append(clean_utterance)\n",
    "assert len(trainset_text) == len(trainset_utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 11118 lines of emotion label in the training set, each line relates to a dialogue\n"
     ]
    }
   ],
   "source": [
    "# Load emotion label in trainset\n",
    "trainset_emotions = []\n",
    "with open('./ijcnlp_dailydialog/train/dialogues_emotion_train.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        trainset_emotions.append(line.strip().split())\n",
    "print(\"Totally {} lines of emotion label in the training set, each line relates to a dialogue\".format(len(trainset_emotions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['0', '0', '0', '0', '0', '0', '4', '4', '4', '4']"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_emotions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that the number of emotion label for each dialogue is the same as the number of utterance in the diaglogue'\n",
    "assert len(trainset_emotions) == len(trainset_text)\n",
    "for i in range(len(trainset_text)):\n",
    "    if len(trainset_emotions[i]) != len(trainset_utterance[i]):\n",
    "        print(trainset_text)\n",
    "        print(trainset_utterance)\n",
    "        print(trainset_emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that in the train set, each utterance already being labeled by an emotion label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the training json file\n",
    "\"\"\" Format of the training json file. Each line in the json file is a dict which contains:\n",
    "    {\"utterance\": [list of text], \"emotion\": [list of emotion label]}\n",
    "\"\"\"\n",
    "with open('./ijcnlp_dailydialog/train/train.json', 'w') as f:\n",
    "    for i in range(len(trainset_text)):\n",
    "        cur_dict = {\"utterance\":trainset_utterance[i], \"emotion\":trainset_emotions[i]}\n",
    "        json.dump(cur_dict, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance_emotion_train = []\n",
    "with open('./ijcnlp_dailydialog/train/train.json', 'r') as fr:\n",
    "    for line in fr:\n",
    "        cur_dict = json.loads(line)\n",
    "        utterance_emotion_train.append(cur_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Valid Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text in validset\n",
    "validset_text = []\n",
    "with open('./ijcnlp_dailydialog/validation/dialogues_validation.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        assert isinstance(line, str)\n",
    "        validset_text.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 1000 lines of data in the validation set, each line forms a dialogue\n"
     ]
    }
   ],
   "source": [
    "print(\"Totally {} lines of data in the validation set, each line forms a dialogue\".format(len(validset_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "\"Good morning , sir . Is there a bank near here ? __eou__ There is one . 5 blocks away from here ? __eou__ Well , that's too far.Can you change some money for me ? __eou__ Surely , of course . What kind of currency have you got ? __eou__ RIB . __eou__ How much would you like to change ? __eou__ 1000 Yuan.Here you are . __eou__\""
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validset_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "validset_utterance = []\n",
    "for i in range(len(validset_text)):\n",
    "    cur_utterance = validset_text[i].split(\"__eou__\")\n",
    "    clean_utterance = []\n",
    "    for i in range(len(cur_utterance)):\n",
    "        if cur_utterance[i] != \"\":\n",
    "            clean_utterance.append(cur_utterance[i].strip())\n",
    "        else:\n",
    "            pass\n",
    "    validset_utterance.append(clean_utterance)\n",
    "assert len(validset_text) == len(validset_utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 1000 lines of emotion label in the validation set, each line relates to a dialogue\n"
     ]
    }
   ],
   "source": [
    "# Load emotion label in trainset\n",
    "validset_emotions = []\n",
    "with open('./ijcnlp_dailydialog/validation/dialogues_emotion_validation.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        validset_emotions.append(line.strip().split())\n",
    "print(\"Totally {} lines of emotion label in the validation set, each line relates to a dialogue\".format(len(validset_emotions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['0', '0', '0', '0', '0', '0', '0']"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validset_emotions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that the number of emotion label for each dialogue is the same as the number of utterance in the diaglogue\n",
    "assert len(validset_emotions) == len(validset_text)\n",
    "for i in range(len(validset_text)):\n",
    "    if len(validset_emotions[i]) != len(validset_utterance[i]):\n",
    "        print(validset_text)\n",
    "        print(validset_utterance)\n",
    "        print(validset_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the training json file\n",
    "\"\"\" Format of the training json file. Each line in the json file is a dict which contains:\n",
    "    {\"utterance\": [list of text], \"emotion\": [list of emotion label]}\n",
    "\"\"\"\n",
    "with open('./ijcnlp_dailydialog/validation/valid.json', 'w') as f:\n",
    "    for i in range(len(validset_text)):\n",
    "        cur_dict = {\"utterance\":validset_utterance[i], \"emotion\":validset_emotions[i]}\n",
    "        json.dump(cur_dict, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text in testset\n",
    "testset_text = []\n",
    "with open('./ijcnlp_dailydialog/test/dialogues_test.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        assert isinstance(line, str)\n",
    "        testset_text.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 1000 lines of data in the test set, each line forms a dialogue\n"
     ]
    }
   ],
   "source": [
    "print(\"Totally {} lines of data in the test set, each line forms a dialogue\".format(len(testset_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Hey man , you wanna buy some weed ? __eou__ Some what ? __eou__ Weed ! You know ? Pot , Ganja , Mary Jane some chronic ! __eou__ Oh , umm , no thanks . __eou__ I also have blow if you prefer to do a few lines . __eou__ No , I am ok , really . __eou__ Come on man ! I even got dope and acid ! Try some ! __eou__ Do you really have all of these drugs ? Where do you get them from ? __eou__ I got my connections ! Just tell me what you want and I â€™ ll even give you one ounce for free . __eou__ Sounds good ! Let â€™ s see , I want . __eou__ Yeah ? __eou__ I want you to put your hands behind your head ! You are under arrest ! __eou__'"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_utterance = []\n",
    "for i in range(len(testset_text)):\n",
    "    cur_utterance = testset_text[i].split(\"__eou__\")\n",
    "    clean_utterance = []\n",
    "    for i in range(len(cur_utterance)):\n",
    "        if cur_utterance[i] != \"\":\n",
    "            clean_utterance.append(cur_utterance[i].strip())\n",
    "        else:\n",
    "            pass\n",
    "    testset_utterance.append(clean_utterance)\n",
    "assert len(testset_text) == len(testset_utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 1000 lines of emotion label in the test set, each line relates to a dialogue\n"
     ]
    }
   ],
   "source": [
    "# Load emotion label in trainset\n",
    "testset_emotions = []\n",
    "with open('./ijcnlp_dailydialog/test/dialogues_emotion_test.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        testset_emotions.append(line.strip().split())\n",
    "print(\"Totally {} lines of emotion label in the test set, each line relates to a dialogue\".format(len(testset_emotions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['0', '6', '0', '0', '0', '0', '0', '0', '0', '0', '3', '0']"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_emotions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that the number of emotion label for each dialogue is the same as the number of utterance in the diaglogue'\n",
    "assert len(testset_emotions) == len(testset_text)\n",
    "for i in range(len(testset_text)):\n",
    "    if len(testset_emotions[i]) != len(testset_utterance[i]):\n",
    "        print(testset_text)\n",
    "        print(testset_utterance)\n",
    "        print(testset_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the training json file\n",
    "\"\"\" Format of the training json file. Each line in the json file is a dict which contains:\n",
    "    {\"utterance\": [list of text], \"emotion\": [list of emotion label]}\n",
    "\"\"\"\n",
    "with open('./ijcnlp_dailydialog/test/test.json', 'w') as f:\n",
    "    for i in range(len(testset_text)):\n",
    "        cur_dict = {\"utterance\":testset_utterance[i], \"emotion\":testset_emotions[i]}\n",
    "        json.dump(cur_dict, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('2019.10': virtualenv)",
   "name": "python374jvsc74a57bd020bbdedb0079e23a85211f14a09dbcc829fefc965ff02508ebf68fe08b48d387"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "20bbdedb0079e23a85211f14a09dbcc829fefc965ff02508ebf68fe08b48d387"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}