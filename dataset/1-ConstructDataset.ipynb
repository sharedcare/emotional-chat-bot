{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sw/centos/anaconda3/2019.10/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DailyDialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_dialog_emotion = {0: \"neutral\", 1: \"anger\", 2: \"disgust\", 3: \"fear\", 4: \"happiness\", 5: \"sadness\", 6: \"surprise\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text in trainset\n",
    "trainset_text = []\n",
    "with open('./ijcnlp_dailydialog/train/dialogues_train.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        assert isinstance(line, str)\n",
    "        trainset_text.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 11118 lines of data in the training set, each line forms a dialogue\n"
     ]
    }
   ],
   "source": [
    "print(\"Totally {} lines of data in the training set, each line forms a dialogue\".format(len(trainset_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Frank â€™ s getting married , do you believe this ? __eou__ Is he really ? __eou__ Yes , he is . He loves the girl very much . __eou__ Who is he marring ? __eou__ A girl he met on holiday in Spain , I think . __eou__ Have they set a date for the wedding ? __eou__ Not yet . __eou__'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_text[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_utterance = []\n",
    "for i in range(len(trainset_text)):\n",
    "    cur_utterance = trainset_text[i].split(\"__eou__\")\n",
    "    clean_utterance = []\n",
    "    for i in range(len(cur_utterance)):\n",
    "        if cur_utterance[i] != \"\":\n",
    "            clean_utterance.append(cur_utterance[i].strip())\n",
    "        else:\n",
    "            pass\n",
    "    trainset_utterance.append(clean_utterance)\n",
    "assert len(trainset_text) == len(trainset_utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 11118 lines of emotion label in the training set, each line relates to a dialogue\n"
     ]
    }
   ],
   "source": [
    "# Load emotion label in trainset\n",
    "trainset_emotions = []\n",
    "with open('./ijcnlp_dailydialog/train/dialogues_emotion_train.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        trainset_emotions.append(line.strip().split())\n",
    "print(\"Totally {} lines of emotion label in the training set, each line relates to a dialogue\".format(len(trainset_emotions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['0', '0', '0', '0', '0', '0', '4', '4', '4', '4']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_emotions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that the number of emotion label for each dialogue is the same as the number of utterance in the diaglogue'\n",
    "assert len(trainset_emotions) == len(trainset_text)\n",
    "for i in range(len(trainset_text)):\n",
    "    if len(trainset_emotions[i]) != len(trainset_utterance[i]):\n",
    "        print(trainset_text)\n",
    "        print(trainset_utterance)\n",
    "        print(trainset_emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that in the train set, each utterance already being labeled by an emotion label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There should be 76052 data instances\n"
     ]
    }
   ],
   "source": [
    "# Let's count how many data instance should there be\n",
    "cnt_data_instance = 0\n",
    "for i in range(len(trainset_emotions)):\n",
    "    cnt_data_instance += (len(trainset_emotions[i]) - 1)\n",
    "print(\"There should be {} data instances\".format(cnt_data_instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_num = 0\n",
    "for i in range(len(trainset_utterance)):\n",
    "    for j in range(len(trainset_utterance[i])):\n",
    "        if user_num == 0:\n",
    "            # add <user0>\n",
    "            trainset_utterance[i][j] = \"<user0> \" + trainset_utterance[i][j]\n",
    "        else:\n",
    "            # add <user1>\n",
    "            trainset_utterance[i][j] = \"<user1> \" + trainset_utterance[i][j]\n",
    "        user_num = (user_num + 1) % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['<user0> Say , Jim , how about going for a few beers after dinner ?',\n '<user1> You know that is tempting but is really not good for our fitness .',\n '<user0> What do you mean ? It will help us to relax .',\n \"<user1> Do you really think so ? I don't . It will just make us fat and act silly . Remember last time ?\",\n \"<user0> I guess you are right.But what shall we do ? I don't feel like sitting at home .\",\n '<user1> I suggest a walk over to the gym where we can play singsong and meet some of our friends .',\n \"<user0> That's a good idea . I hear Mary and Sally often go there to play pingpong.Perhaps we can make a foursome with them .\",\n '<user1> Sounds great to me ! If they are willing , we could ask them to go dancing with us.That is excellent exercise and fun , too .',\n \"<user0> Good.Let ' s go now .\",\n '<user1> All right .']"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_utterance[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['<user0> Can you do push-ups ?',\n \"<user1> Of course I can . It's a piece of cake ! Believe it or not , I can do 30 push-ups a minute .\",\n \"<user0> Really ? I think that's impossible !\",\n '<user1> You mean 30 push-ups ?',\n '<user0> Yeah !',\n \"<user1> It's easy . If you do exercise everyday , you can make it , too .\"]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_utterance[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_instances = []\n",
    "for i in range(len(trainset_utterance)):\n",
    "    assert len(trainset_utterance[i]) == len(trainset_emotions[i])\n",
    "    assert len(trainset_utterance[i]) > 1\n",
    "    for j in range(1, len(trainset_utterance[i])):\n",
    "        src_text = \" __eou__ \".join(trainset_utterance[i][:j])\n",
    "        trg_text = trainset_utterance[i][j]\n",
    "        trg_emotion = daily_dialog_emotion[int(trainset_emotions[i][j])]\n",
    "        cur_instance = {\"src\": src_text, \"trg\": trg_text, \"trg_emotion\": trg_emotion}\n",
    "        trainset_instances.append(cur_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[{'src': '<user0> Say , Jim , how about going for a few beers after dinner ?',\n  'trg': '<user1> You know that is tempting but is really not good for our fitness .',\n  'trg_emotion': 'neutral'},\n {'src': '<user0> Say , Jim , how about going for a few beers after dinner ? __eou__ <user1> You know that is tempting but is really not good for our fitness .',\n  'trg': '<user0> What do you mean ? It will help us to relax .',\n  'trg_emotion': 'neutral'},\n {'src': '<user0> Say , Jim , how about going for a few beers after dinner ? __eou__ <user1> You know that is tempting but is really not good for our fitness . __eou__ <user0> What do you mean ? It will help us to relax .',\n  'trg': \"<user1> Do you really think so ? I don't . It will just make us fat and act silly . Remember last time ?\",\n  'trg_emotion': 'neutral'}]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset_instances[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 76052 lines of data in the trainset.\n"
     ]
    }
   ],
   "source": [
    "# Construct the training json file\n",
    "\"\"\" Format of the training json file. Each line in the json file is a dict which contains:\n",
    "    {\"src\": text in the historty, \"trg\": text need to be generated in response, \"trg_emotion\": target emotion}\n",
    "\"\"\"\n",
    "cnt_lines = 0\n",
    "with open('./ijcnlp_dailydialog/train/train.json', 'w') as f:\n",
    "    for trainset_instance in trainset_instances:\n",
    "        json.dump(trainset_instance, f)\n",
    "        f.write('\\n')\n",
    "        cnt_lines += 1\n",
    "print(\"Totally {} lines of data in the trainset.\".format(cnt_lines))\n",
    "assert cnt_lines == cnt_data_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Valid Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text in validset\n",
    "validset_text = []\n",
    "with open('./ijcnlp_dailydialog/validation/dialogues_validation.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        assert isinstance(line, str)\n",
    "        validset_text.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 1000 lines of data in the validation set, each line forms a dialogue\n"
     ]
    }
   ],
   "source": [
    "print(\"Totally {} lines of data in the validation set, each line forms a dialogue\".format(len(validset_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "\"Good morning , sir . Is there a bank near here ? __eou__ There is one . 5 blocks away from here ? __eou__ Well , that's too far.Can you change some money for me ? __eou__ Surely , of course . What kind of currency have you got ? __eou__ RIB . __eou__ How much would you like to change ? __eou__ 1000 Yuan.Here you are . __eou__\""
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validset_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "validset_utterance = []\n",
    "for i in range(len(validset_text)):\n",
    "    cur_utterance = validset_text[i].split(\"__eou__\")\n",
    "    clean_utterance = []\n",
    "    for i in range(len(cur_utterance)):\n",
    "        if cur_utterance[i] != \"\":\n",
    "            clean_utterance.append(cur_utterance[i].strip())\n",
    "        else:\n",
    "            pass\n",
    "    validset_utterance.append(clean_utterance)\n",
    "assert len(validset_text) == len(validset_utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 1000 lines of emotion label in the validation set, each line relates to a dialogue\n"
     ]
    }
   ],
   "source": [
    "# Load emotion label in trainset\n",
    "validset_emotions = []\n",
    "with open('./ijcnlp_dailydialog/validation/dialogues_emotion_validation.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        validset_emotions.append(line.strip().split())\n",
    "print(\"Totally {} lines of emotion label in the validation set, each line relates to a dialogue\".format(len(validset_emotions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['0', '0', '0', '0', '0', '0', '0']"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validset_emotions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that the number of emotion label for each dialogue is the same as the number of utterance in the diaglogue\n",
    "assert len(validset_emotions) == len(validset_text)\n",
    "for i in range(len(validset_text)):\n",
    "    if len(validset_emotions[i]) != len(validset_utterance[i]):\n",
    "        print(validset_text)\n",
    "        print(validset_utterance)\n",
    "        print(validset_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_num = 0\n",
    "for i in range(len(validset_utterance)):\n",
    "    for j in range(len(validset_utterance[i])):\n",
    "        if user_num == 0:\n",
    "            # add <user0>\n",
    "            validset_utterance[i][j] = \"<user0> \" + validset_utterance[i][j]\n",
    "        else:\n",
    "            # add <user1>\n",
    "            validset_utterance[i][j] = \"<user1> \" + validset_utterance[i][j]\n",
    "        user_num = (user_num + 1) % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['<user0> Good morning , sir . Is there a bank near here ?',\n '<user1> There is one . 5 blocks away from here ?',\n \"<user0> Well , that's too far.Can you change some money for me ?\",\n '<user1> Surely , of course . What kind of currency have you got ?',\n '<user0> RIB .',\n '<user1> How much would you like to change ?',\n '<user0> 1000 Yuan.Here you are .']"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validset_utterance[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "validset_instances = []\n",
    "for i in range(len(validset_utterance)):\n",
    "    assert len(validset_utterance[i]) == len(validset_emotions[i])\n",
    "    assert len(validset_utterance[i]) > 1\n",
    "    for j in range(1, len(validset_utterance[i])):\n",
    "        src_text = \" __eou__ \".join(validset_utterance[i][:j])\n",
    "        trg_text = validset_utterance[i][j]\n",
    "        trg_emotion = daily_dialog_emotion[int(validset_emotions[i][j])]\n",
    "        cur_instance = {\"src\": src_text, \"trg\": trg_text, \"trg_emotion\": trg_emotion}\n",
    "        validset_instances.append(cur_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[{'src': '<user0> Good morning , sir . Is there a bank near here ?',\n  'trg': '<user1> There is one . 5 blocks away from here ?',\n  'trg_emotion': 'neutral'},\n {'src': '<user0> Good morning , sir . Is there a bank near here ? __eou__ <user1> There is one . 5 blocks away from here ?',\n  'trg': \"<user0> Well , that's too far.Can you change some money for me ?\",\n  'trg_emotion': 'neutral'},\n {'src': \"<user0> Good morning , sir . Is there a bank near here ? __eou__ <user1> There is one . 5 blocks away from here ? __eou__ <user0> Well , that's too far.Can you change some money for me ?\",\n  'trg': '<user1> Surely , of course . What kind of currency have you got ?',\n  'trg_emotion': 'neutral'}]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validset_instances[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There should be 7069 lines of data in valid set\n",
      "Totally 7069 lines of data in the validset.\n"
     ]
    }
   ],
   "source": [
    "# Construct the training json file\n",
    "\"\"\" Format of the training json file. Each line in the json file is a dict which contains:\n",
    "    {\"src\": text in the historty, \"trg\": text need to be generated in response, \"trg_emotion\": target emotion}\n",
    "\"\"\"\n",
    "# Let's first compute how many data instance should there be\n",
    "cnt_data_instance = 0\n",
    "for i in range(len(validset_emotions)):\n",
    "    cnt_data_instance += len(validset_emotions[i]) - 1\n",
    "print('There should be {} lines of data in valid set'.format(cnt_data_instance))\n",
    "cnt_lines = 0\n",
    "with open('./ijcnlp_dailydialog/validation/valid.json', 'w') as f:\n",
    "    for validset_instance in validset_instances:\n",
    "        json.dump(validset_instance, f)\n",
    "        f.write('\\n')\n",
    "        cnt_lines += 1\n",
    "assert cnt_lines == cnt_data_instance\n",
    "print(\"Totally {} lines of data in the validset.\".format(cnt_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text in testset\n",
    "testset_text = []\n",
    "with open('./ijcnlp_dailydialog/test/dialogues_test.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        assert isinstance(line, str)\n",
    "        testset_text.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 1000 lines of data in the test set, each line forms a dialogue\n"
     ]
    }
   ],
   "source": [
    "print(\"Totally {} lines of data in the test set, each line forms a dialogue\".format(len(testset_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'Hey man , you wanna buy some weed ? __eou__ Some what ? __eou__ Weed ! You know ? Pot , Ganja , Mary Jane some chronic ! __eou__ Oh , umm , no thanks . __eou__ I also have blow if you prefer to do a few lines . __eou__ No , I am ok , really . __eou__ Come on man ! I even got dope and acid ! Try some ! __eou__ Do you really have all of these drugs ? Where do you get them from ? __eou__ I got my connections ! Just tell me what you want and I â€™ ll even give you one ounce for free . __eou__ Sounds good ! Let â€™ s see , I want . __eou__ Yeah ? __eou__ I want you to put your hands behind your head ! You are under arrest ! __eou__'"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_utterance = []\n",
    "for i in range(len(testset_text)):\n",
    "    cur_utterance = testset_text[i].split(\"__eou__\")\n",
    "    clean_utterance = []\n",
    "    for i in range(len(cur_utterance)):\n",
    "        if cur_utterance[i] != \"\":\n",
    "            clean_utterance.append(cur_utterance[i].strip())\n",
    "        else:\n",
    "            pass\n",
    "    testset_utterance.append(clean_utterance)\n",
    "assert len(testset_text) == len(testset_utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 1000 lines of emotion label in the test set, each line relates to a dialogue\n"
     ]
    }
   ],
   "source": [
    "# Load emotion label in trainset\n",
    "testset_emotions = []\n",
    "with open('./ijcnlp_dailydialog/test/dialogues_emotion_test.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        testset_emotions.append(line.strip().split())\n",
    "print(\"Totally {} lines of emotion label in the test set, each line relates to a dialogue\".format(len(testset_emotions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['0', '6', '0', '0', '0', '0', '0', '0', '0', '0', '3', '0']"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_emotions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that the number of emotion label for each dialogue is the same as the number of utterance in the diaglogue'\n",
    "assert len(testset_emotions) == len(testset_text)\n",
    "for i in range(len(testset_text)):\n",
    "    if len(testset_emotions[i]) != len(testset_utterance[i]):\n",
    "        print(testset_text)\n",
    "        print(testset_utterance)\n",
    "        print(testset_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_num = 0\n",
    "for i in range(len(testset_utterance)):\n",
    "    for j in range(len(testset_utterance[i])):\n",
    "        if user_num == 0:\n",
    "            # add <user0>\n",
    "            testset_utterance[i][j] = \"<user0> \" + testset_utterance[i][j]\n",
    "        else:\n",
    "            # add <user1>\n",
    "            testset_utterance[i][j] = \"<user1> \" + testset_utterance[i][j]\n",
    "        user_num = (user_num + 1) % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['<user0> Hey man , you wanna buy some weed ?',\n '<user1> Some what ?',\n '<user0> Weed ! You know ? Pot , Ganja , Mary Jane some chronic !',\n '<user1> Oh , umm , no thanks .',\n '<user0> I also have blow if you prefer to do a few lines .',\n '<user1> No , I am ok , really .',\n '<user0> Come on man ! I even got dope and acid ! Try some !',\n '<user1> Do you really have all of these drugs ? Where do you get them from ?',\n '<user0> I got my connections ! Just tell me what you want and I â€™ ll even give you one ounce for free .',\n '<user1> Sounds good ! Let â€™ s see , I want .',\n '<user0> Yeah ?',\n '<user1> I want you to put your hands behind your head ! You are under arrest !']"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_utterance[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_instances = []\n",
    "for i in range(len(testset_utterance)):\n",
    "    assert len(testset_utterance[i]) == len(testset_emotions[i])\n",
    "    assert len(testset_utterance[i]) > 1\n",
    "    for j in range(1, len(testset_utterance[i])):\n",
    "        src_text = \" __eou__ \".join(testset_utterance[i][:j])\n",
    "        trg_text = testset_utterance[i][j]\n",
    "        trg_emotion = daily_dialog_emotion[int(testset_emotions[i][j])]\n",
    "        cur_instance = {\"src\": src_text, \"trg\": trg_text, \"trg_emotion\": trg_emotion}\n",
    "        testset_instances.append(cur_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[{'src': '<user0> Hey man , you wanna buy some weed ?',\n  'trg': '<user1> Some what ?',\n  'trg_emotion': 'surprise'},\n {'src': '<user0> Hey man , you wanna buy some weed ? __eou__ <user1> Some what ?',\n  'trg': '<user0> Weed ! You know ? Pot , Ganja , Mary Jane some chronic !',\n  'trg_emotion': 'neutral'},\n {'src': '<user0> Hey man , you wanna buy some weed ? __eou__ <user1> Some what ? __eou__ <user0> Weed ! You know ? Pot , Ganja , Mary Jane some chronic !',\n  'trg': '<user1> Oh , umm , no thanks .',\n  'trg_emotion': 'neutral'}]"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_instances[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There should be 6740 lines of data in valid set\n",
      "Totally 6740 lines of data in the testset.\n"
     ]
    }
   ],
   "source": [
    "# Construct the training json file\n",
    "\"\"\" Format of the training json file. Each line in the json file is a dict which contains:\n",
    "    {\"utterance\": [list of text], \"emotion\": [list of emotion label]}\n",
    "\"\"\"\n",
    "# Let's first compute how many data instance should there be\n",
    "cnt_data_instance = 0\n",
    "for i in range(len(testset_emotions)):\n",
    "    cnt_data_instance += len(testset_emotions[i]) - 1\n",
    "print('There should be {} lines of data in valid set'.format(cnt_data_instance))\n",
    "cnt_lines = 0\n",
    "with open('./ijcnlp_dailydialog/test/test.json', 'w') as f:\n",
    "    for testset_instance in testset_instances:\n",
    "        json.dump(testset_instance, f)\n",
    "        f.write('\\n')\n",
    "        cnt_lines += 1\n",
    "assert cnt_lines == cnt_data_instance\n",
    "print(\"Totally {} lines of data in the testset.\".format(cnt_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empathetic Dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    with open(path) as f:\n",
    "        cache = f.readline().split(',')[0] \n",
    "        corpus, history = [], []\n",
    "        emotion = []\n",
    "        user = 0\n",
    "        for line in f.readlines():\n",
    "            items = line.strip().split(',')\n",
    "            utterance = f'<user{user}> ' + items[5].replace('_comma_', ',')\n",
    "            utterance = utterance.strip()\n",
    "            current_emotion = items[2]\n",
    "            if items[0] == cache:\n",
    "                history.append(utterance)\n",
    "                emotion.append(current_emotion)\n",
    "            else:\n",
    "                if history:\n",
    "                    assert len(history) == len(emotion)\n",
    "                    corpus.append((history, emotion))    # append the dialogue\n",
    "                history = [utterance]\n",
    "                emotion = [current_emotion]\n",
    "            user = 1 if user == 0 else 0\n",
    "            cache = items[0]\n",
    "\n",
    "    avg_turn = np.mean([len(i[0]) for i in corpus])\n",
    "    max_turn = max([len(i[0]) for i in corpus])\n",
    "    min_turn = min([len(i[0]) for i in corpus])\n",
    "    print(f'[!] find {len(corpus)} dialogue, turns(avg/max/min): {avg_turn}/{max_turn}/{min_turn}')\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(mode, corpus):\n",
    "    with open('{}.json'.format(mode), 'w') as f:\n",
    "        for data_chunk in corpus:\n",
    "            dialog = data_chunk[0]\n",
    "            emotion = data_chunk[1]\n",
    "            for i in range(1, len(dialog)):\n",
    "                src_text = ' __eou__ '.join(dialog[:i])\n",
    "                trg_text = dialog[i]\n",
    "                cur_emotion = emotion[i]\n",
    "                cur_data_instance = {'src':src_text, 'trg':trg_text, 'trg_emotion':cur_emotion}\n",
    "                json.dump(cur_data_instance, f)\n",
    "                f.write('\\n')\n",
    "\n",
    "    print(f'[!] write into {mode} file over ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] find 19532 dialogue, turns(avg/max/min): 4.309082531230801/8/1\n",
      "[!] write into train file over ...\n"
     ]
    }
   ],
   "source": [
    "train_data = load_file('EmpatheticDialog/train.csv')\n",
    "write_file('train', train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] find 2769 dialogue, turns(avg/max/min): 4.360418923799205/8/1\n",
      "[!] write into valid file over ...\n",
      "[!] find 2546 dialogue, turns(avg/max/min): 4.308326787117046/8/2\n",
      "[!] write into test file over ...\n"
     ]
    }
   ],
   "source": [
    "valid_data = load_file('EmpatheticDialog/valid.csv')\n",
    "write_file('valid', valid_data)\n",
    "test_data = load_file('EmpatheticDialog/test.csv')\n",
    "write_file('test', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('2019.10': virtualenv)",
   "name": "python374jvsc74a57bd020bbdedb0079e23a85211f14a09dbcc829fefc965ff02508ebf68fe08b48d387"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "20bbdedb0079e23a85211f14a09dbcc829fefc965ff02508ebf68fe08b48d387"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}